{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0fmWxS1C6oJW/+uhmkddT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHD6kr1b3pik",
        "outputId": "fe55678b-7424-4f91-a48d-b75160dab1fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import tiktoken\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import re"
      ],
      "metadata": {
        "id": "6ftLOSWi_4N0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "  raw_text = f.read()\n",
        "print(\"Total number of character:\", len(raw_text))\n",
        "print(raw_text[:99])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtkgfOgJAA3c",
        "outputId": "0d30e19d-4bcb-496c-bf7c-b63e9a3c095e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of character: 20479\n",
            "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, world. This, is a test.\"\n",
        "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "result = [item.strip() for item in result if item.strip()]\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpuyOEl5ACOw",
        "outputId": "b4da282e-ddcf-4a01-d3f1-681ca7aa2f05"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
        "result = [item.strip() for item in result if item.strip()]\n",
        "print(len(result))\n",
        "print(len(np.unique(result)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHClSulEDsbU",
        "outputId": "c65b27aa-ebc8-47fd-dfe3-eba9d97c18cb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4690\n",
            "1130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = np.sort(np.unique([word for word in result]))\n",
        "word_2_idx = {w:v for v,w in enumerate(vocab)}"
      ],
      "metadata": {
        "id": "vqVk5qcTFITO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tokenizer_V1:\n",
        "  def __init__(self, vocab: list):\n",
        "    self.word2idx = {w:v for v,w in enumerate(vocab)}\n",
        "    self.word2idx[\"<unk>\"] = len(vocab) + 1\n",
        "    self.word2idx[\"<eot>\"] = self.word2idx[\"<unk>\"] +1\n",
        "    self.idx2word = {v:k for k,v in self.word2idx.items()}\n",
        "\n",
        "  def encode(self, text: str):\n",
        "    result = re.split(r'([,.:;?_!\"()\\']|--|\\s)', text)\n",
        "    result = [item.strip() for item in result if item.strip()]\n",
        "    return [self.word2idx[token] if token in self.word2idx else self.word2idx[\"<unk>\"] for token in result] + [self.word2idx[\"<eot>\"]]\n",
        "\n",
        "  def decode(self, ids: list):\n",
        "    text = \" \".join([self.idx2word[id] for id in ids])\n",
        "    text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "n1Ref-hXAM0S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I am a loser.\"\n",
        "tokenizer = Tokenizer_V1(vocab)\n",
        "ids = tokenizer.encode(text)\n",
        "words = tokenizer.decode(ids)\n",
        "print(text)\n",
        "print(ids)\n",
        "print(words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA_YIcL0Ay7H",
        "outputId": "e84cd54f-4620-463d-9c3e-374b85cdf3c9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am a loser.\n",
            "[53, 150, 115, 1131, 7, 1132]\n",
            "I am a <unk>. <eot>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "B9ks4_NFMUYA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc_text = tokenizer.encode(raw_text)\n",
        "print(len(enc_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPYjBuASEQiL",
        "outputId": "4462d64c-b748-4191-b807-342e3a0f176b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_data_chunks(encoded: list, context_length: int):\n",
        "  inputs = []\n",
        "  targets = []\n",
        "  num_chunks = (len(encoded) - 1) // context_length\n",
        "  for i in range(num_chunks):\n",
        "    input, target = encoded[i*context_length: (i+1)*context_length], encoded[i*context_length + 1: (i+1)*context_length + 1]\n",
        "    inputs.append(input)\n",
        "    targets.append(target)\n",
        "\n",
        "  return torch.tensor(inputs), torch.tensor(targets)"
      ],
      "metadata": {
        "id": "_Zr7XdOQGrFY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = create_data_chunks(enc_text, 12)\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "print(X[0])\n",
        "print(Y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qriEX-j6-HHL",
        "outputId": "9c808a2e-b198-4ae1-a188-5b8c3a78f406"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([428, 12])\n",
            "torch.Size([428, 12])\n",
            "tensor([   40,   367,  2885,  1464,  1807,  3619,   402,   271, 10899,  2138,\n",
            "          257,  7026])\n",
            "tensor([  367,  2885,  1464,  1807,  3619,   402,   271, 10899,  2138,   257,\n",
            "         7026, 15632])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, text, tokenizer, max_length, stride):\n",
        "    self.input_ids = []\n",
        "    self.target_ids  = []\n",
        "\n",
        "    token_ids = tokenizer.encode(text)\n",
        "    for i in range(0, len(token_ids) - max_length, stride):\n",
        "      inputs, outputs = token_ids[i: i+max_length], token_ids[i+1: i+max_length+1]\n",
        "      self.input_ids.append(torch.tensor(inputs))\n",
        "      self.target_ids.append(torch.tensor(outputs))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "MS1TrSlQ-SmY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader(text, tokenizer, max_length, stride, batch_size, shuffle=True, drop_last=True):\n",
        "  dataset = GPTDataset(text, tokenizer,  max_length, stride)\n",
        "  return torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)"
      ],
      "metadata": {
        "id": "64Qau54PEKLl"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader = create_dataloader(raw_text, tokenizer, batch_size=4, max_length=32, stride=1, shuffle=False)"
      ],
      "metadata": {
        "id": "Yze_aCtgEtKy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = next(iter(dataloader))\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACnUH4BZE3xy",
        "outputId": "6a4601b4-d1ea-4ce5-aedc-94f1957d897e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emb_layer = torch.nn.Embedding(num_embeddings=tokenizer.n_vocab, embedding_dim=16)"
      ],
      "metadata": {
        "id": "DRM8wfTeE9-F"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = emb_layer(x)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkHoSBRsHGeH",
        "outputId": "ded89f18-245e-4f99-df89-033a84a3c749"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 32, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_setup.py\n",
        "import torch\n",
        "import tiktoken\n",
        "\n",
        "\n",
        "class GPTDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,\n",
        "               txt: str,\n",
        "               tokenizer: tiktoken.Encoding,\n",
        "               max_length: int,\n",
        "               stride: int):\n",
        "    self.input_ids = []\n",
        "    self.target_ids = []\n",
        "    token_ids = tokenizer.encode(txt)\n",
        "\n",
        "    for i in range(0, len(token_ids) - max_length, stride):\n",
        "      input_chunk = token_ids[i: i+max_length]\n",
        "      target_chunk = token_ids[i+1: i+1+max_length]\n",
        "      self.input_ids.append(torch.tensor(input_chunk))\n",
        "      self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.input_ids)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.input_ids[idx], self.target_ids[idx]\n",
        "\n",
        "\n",
        "def create_dataloader(txt, tokenizer, max_length=256, stride=128, batch_size=4, shuffle=True, drop_last=True, num_workers=0):\n",
        "  dataset = GPTDataset(txt, tokenizer, max_length, stride)\n",
        "  dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last, num_workers=num_workers)\n",
        "  return dataloader\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRPQpBS6HI33",
        "outputId": "6a05ae5d-b9ee-4a35-d6e2-daef457dee9e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = 32\n",
        "embedding_dim = 16\n",
        "\n",
        "emb_layer = torch.nn.Embedding(num_embeddings=tokenizer.n_vocab, embedding_dim=embedding_dim)\n",
        "pos_encoding_layer = torch.nn.Embedding(context_length, embedding_dim)\n",
        "pos_enc = pos_encoding_layer(torch.arange(context_length))\n",
        "\n",
        "out = emb_layer(x) + pos_enc\n",
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5vS4ymuRwr0",
        "outputId": "da7da92f-896d-4ad0-a9dd-b9f8667905fe"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 32, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = torch.tensor(\n",
        "[[0.43, 0.15, 0.89], # Your (x^1)\n",
        "[0.55, 0.87, 0.66], # journey (x^2)\n",
        "[0.57, 0.85, 0.64], # starts (x^3)\n",
        "[0.22, 0.58, 0.33], # with (x^4)\n",
        "[0.77, 0.25, 0.10], # one (x^5)\n",
        "[0.05, 0.80, 0.55]] # step (x^6)\n",
        ")"
      ],
      "metadata": {
        "id": "PgciZ_lrTpsx"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmUIQmJzD5t1",
        "outputId": "80311ac0-1a98-4af5-9fe4-6e04b1270bfb"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dpa = inputs @ inputs.T\n",
        "attention_weights = torch.softmax(dpa, dim=-1)\n",
        "context_vecs = attention_weights @ inputs\n",
        "print(context_vecs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCnnubccD8Kz",
        "outputId": "4af0a065-0ab4-4ccf-b0d8-a102f9dc9608"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4421, 0.5931, 0.5790],\n",
            "        [0.4419, 0.6515, 0.5683],\n",
            "        [0.4431, 0.6496, 0.5671],\n",
            "        [0.4304, 0.6298, 0.5510],\n",
            "        [0.4671, 0.5910, 0.5266],\n",
            "        [0.4177, 0.6503, 0.5645]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.sum([0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLJSCFJMFNwH",
        "outputId": "14f4dbbb-d30e-466b-ba38-9526eff96fb5"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionV1(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    d = torch.tensor(inputs.shape[-1])\n",
        "    Q, K, V = inputs, inputs, inputs\n",
        "    attention_scores = Q @ K.transpose(-1, -2)/torch.sqrt(d)\n",
        "    attention_weights = torch.softmax(attention_scores, dim=-1)\n",
        "    return attention_weights @ V"
      ],
      "metadata": {
        "id": "k3V3l06oFhm_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionV2(nn.Module):\n",
        "  def __init__(self, d: int, qkv_bias: bool=False):\n",
        "    super().__init__()\n",
        "    self.d = torch.tensor(d)\n",
        "    self.Wq = nn.Linear(d, d, bias=qkv_bias)\n",
        "    self.Wk = nn.Linear(d, d, bias=qkv_bias)\n",
        "    self.Wv = nn.Linear(d, d, bias=qkv_bias)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    Q = self.Wq(inputs)\n",
        "    K = self.Wk(inputs)\n",
        "    V = self.Wv(inputs)\n",
        "    attention_scores = Q @ K.transpose(-1, -2)/torch.sqrt(self.d)\n",
        "    attention_weights = torch.softmax(attention_scores, dim=-1)\n",
        "    return attention_weights @ V"
      ],
      "metadata": {
        "id": "rCpXEedWPQ1H"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalSelfAttention(nn.Module):\n",
        "  def __init__(self,\n",
        "               context_length: int,\n",
        "               d: int,\n",
        "               qkv_bias: bool=False) -> None:\n",
        "    super().__init__()\n",
        "    self.d = torch.tensor(d)\n",
        "    self.Wq = nn.Linear(d, d, bias=qkv_bias)\n",
        "    self.Wk = nn.Linear(d, d, bias=qkv_bias)\n",
        "    self.Wv = nn.Linear(d, d, bias=qkv_bias)\n",
        "    self.mask = torch.triu(torch.ones(context_length, context_length), diagonal=1)\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    Q = self.Wq(inputs)\n",
        "    K = self.Wk(inputs)\n",
        "    V = self.Wv(inputs)\n",
        "    attention_scores = Q @ K.transpose(-1, -2)/torch.sqrt(self.d)\n",
        "    masked = attention_scores.masked_fill(self.mask.bool(), -torch.inf)\n",
        "    attention_weights = torch.softmax(masked, dim=-1)\n",
        "    print(masked)\n",
        "    print(attention_weights)\n",
        "    return attention_weights @ V\n",
        "\n"
      ],
      "metadata": {
        "id": "HTOr07KtRWkM"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l = CausalSelfAttention(6, 3, False)\n",
        "input = inputs.unsqueeze(0)\n",
        "out = l(input)\n",
        "print(input.shape)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVb7oDHMG5zh",
        "outputId": "a78468bf-cfba-443a-9ade-dc7fa267b223"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-0.2636,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
            "         [-0.3517, -0.3221,    -inf,    -inf,    -inf,    -inf],\n",
            "         [-0.3477, -0.3169, -0.3095,    -inf,    -inf,    -inf],\n",
            "         [-0.1904, -0.1737, -0.1702, -0.0888,    -inf,    -inf],\n",
            "         [-0.1783, -0.1342, -0.1286, -0.0722,  0.0102,    -inf],\n",
            "         [-0.2419, -0.2359, -0.2324, -0.1199, -0.1026, -0.1637]]],\n",
            "       grad_fn=<MaskedFillBackward0>)\n",
            "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.4926, 0.5074, 0.0000, 0.0000, 0.0000, 0.0000],\n",
            "         [0.3257, 0.3359, 0.3384, 0.0000, 0.0000, 0.0000],\n",
            "         [0.2413, 0.2454, 0.2462, 0.2671, 0.0000, 0.0000],\n",
            "         [0.1847, 0.1930, 0.1941, 0.2053, 0.2230, 0.0000],\n",
            "         [0.1568, 0.1578, 0.1583, 0.1772, 0.1803, 0.1696]]],\n",
            "       grad_fn=<SoftmaxBackward0>)\n",
            "torch.Size([1, 6, 3])\n",
            "torch.Size([1, 6, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = torch.triu(torch.ones(3,3)*-torch.inf, diagonal=1)\n",
        "torch.softmax(temp, dim=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8a3buNnHJGs",
        "outputId": "840586d4-fc90-4c01-82af-73493a1b3d5a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000],\n",
              "        [0.5000, 0.5000, 0.0000],\n",
              "        [0.3333, 0.3333, 0.3333]])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cleOMSpyZ6Gl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}