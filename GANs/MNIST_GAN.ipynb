{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBCNnspyVHE56tPgRFfUpl"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8EykaZQsnJP"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, in_features: int=784):\n",
        "    super().__init__()\n",
        "    self.disc = nn.Sequential(\n",
        "        nn.Linear(in_features, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(128, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.disc(x)\n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, latent_dim: int = 64, out_features: int=784):\n",
        "    super().__init__()\n",
        "    self.gen = nn.Sequential(\n",
        "        nn.Linear(latent_dim, 256),\n",
        "        nn.LeakyReLU(0.2),\n",
        "        nn.Linear(256, out_features),\n",
        "        nn.Tanh()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.gen(x)\n"
      ],
      "metadata": {
        "id": "YK0Yoog1wxWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5),(0.5))])\n",
        "dataset = datasets.MNIST(root = 'data/', download = True, transform=transform)\n",
        "train_dl = DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "xoEdhYsl1nmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_step(discriminator, opt_d, generator, real_images, batch_size, latent_dim):\n",
        "  real_preds = discriminator(real_images)\n",
        "  real_targets = torch.ones_like(real_preds)\n",
        "  real_loss = torch.nn.functional.binary_cross_entropy(real_preds, real_targets)\n",
        "\n",
        "  latents = torch.randn(size=(batch_size, latent_dim))\n",
        "  fake_images = generator(latents)\n",
        "  fake_preds = discriminator(fake_images)\n",
        "  fake_targets = torch.zeros_like(fake_preds)\n",
        "  fake_loss = torch.nn.functional.binary_cross_entropy(fake_preds, fake_targets)\n",
        "\n",
        "  opt_d.zero_grad()\n",
        "  loss = real_loss + fake_loss\n",
        "  loss.backward()\n",
        "  opt_d.step()\n",
        "\n",
        "\n",
        "def generator_step(generator, opt_g, discriminator, batch_size, latent_dim):\n",
        "  latents = torch.randn(size=(batch_size, latent_dim))\n",
        "  fake_images = generator(latents)\n",
        "  fake_preds = discriminator(fake_images)\n",
        "  fake_targets = torch.ones_like(fake_preds)\n",
        "  loss = torch.nn.functional.binary_cross_entropy(fake_preds, fake_targets)\n",
        "\n",
        "  opt_g.zero_grad()\n",
        "  loss.backward()\n",
        "  opt_g.step()\n",
        "\n",
        "\n",
        "def train(generator,\n",
        "          discriminator,\n",
        "          train_dl,\n",
        "          batch_size,\n",
        "          latent_dim,\n",
        "          num_epochs):\n",
        "  opt_d = torch.optim.Adam(discriminator.parameters(), lr=1e-4)\n",
        "  opt_g = torch.optim.Adam(generator.parameters(), lr=1e-4)\n",
        "  fixed_latents = torch.randn(size=(64, latent_dim))\n",
        "\n",
        "  with torch.inference_mode():\n",
        "    fake_images = generator(fixed_latents)\n",
        "    fake_images = torch.reshape(fake_images, (64, 1, 28, 28))\n",
        "    image = (torchvision.utils.make_grid(fake_images.detach()[:64], nrow=8) + 1.0)/2.0\n",
        "    plt.figure(figsize=(8,8))\n",
        "    plt.imshow(image.permute(1,2,0))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "  for epoch in range(num_epochs):\n",
        "    print(f\"Starting epoch {epoch + 1} of {num_epochs}...\")\n",
        "    for xb, yb in train_dl:\n",
        "      xb = torch.reshape(xb, (xb.shape[0], -1))\n",
        "      discriminator_step(discriminator, opt_d, generator, xb, batch_size, latent_dim)\n",
        "      generator_step(generator, opt_g, discriminator, batch_size, latent_dim)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "      fake_images = generator(fixed_latents)\n",
        "      fake_images = torch.reshape(fake_images, (64, 1, 28, 28))\n",
        "      image = (torchvision.utils.make_grid(fake_images.detach()[:64], nrow=8) + 1.0)/2.0\n",
        "      plt.figure(figsize=(8,8))\n",
        "      plt.imshow(image.permute(1,2,0))\n",
        "      plt.axis('off')\n",
        "      plt.show()"
      ],
      "metadata": {
        "id": "1YdH_71A3AeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disc = Discriminator()\n",
        "gen = Generator()\n",
        "train(gen, disc, train_dl, 64, 64, 50)"
      ],
      "metadata": {
        "id": "NobqUbj98eFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s-URd-8c83Jk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}